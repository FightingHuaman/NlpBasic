基于DbPedia模糊查询推荐算法及其在极地共享平台中的应用

摘　要：为了不断推广我国极地标本资源服务，有效地引导用户逐步靠近他所需要的信息，通过分析搜索引擎中的查询推荐的特点，提出了基于DbPedia的模糊查询算法，即通过构建DbPedia类别树查找相似的词条队列，然后利用模糊匹配算法计算出词条相似度，并给出此算法在极地资源共享平台中的实例查询应用。实验结果表明,与传统逐字字符匹配方法和DBpedia语义相似度算法相比，由于模糊权值的调节，基于DbPedia的模糊查询算法的查找准确率高、抗干扰能力强、算法使用灵活。

关键字：查询；搜索引擎；模糊查询；语义相似度
1 引言
搜索引擎作为信息平台最重要的模块之一，其中的查询推荐又几乎成为搜索模块的标配功能。尤其当用户对检索目标模糊不清的时候，通过搜索引擎给予的相关检索结果，可以有效地引导用户逐步靠近他所需要的信息[1]。在最近的十多年了，查询推荐技术在电子商务平台获取到非常好的效果，因此，为了提高数据的使用价值，本文提出了将查询推荐技术应用到极地标本资源共享平台中。极地标本资源共享平台于2006年建立，目前平台已经发布6326条资源、9607张图片，3.8G数据量，日平均用户888人，总点击数达4434万次，总下载量达12TB，有来自165个国家的用户访问平台。为了不断推广我国极地标本资源服务，给那些试图开展相关的极地研究而又没能去现场的科学家提供更多的标本及其信息，提高极地珍贵标本资源的利用效率，本文基于维基百科知识库设计了模糊查询推荐算法，并应用于极地标本资源共享平台[2]。
由于科学数据平台的用户量相对电子商务平台较少，产生的用户日志简单，因此本文基于内容进行查询推荐[3]。另外，本文充分考虑搜索引擎作为信息平台最重要的因素之一，以及字或词的关联特点[4]，提出了基于DbPedia的模糊查询算法，即通过构建DbPedia类别树找对相似的词条队列，然后利用模糊匹配算法计算出词条相似度，并给出此算法在极地资源共享平台中的实例查询应用。
2 算法
2.1  语义相似类别树构建
    知识库的建立是一个涵盖大量学科，复杂而庞大的工作，本文基于DBpedia建立关联数据知识库[5-7]，具备特点：
l 它的词源是基于维基百科Wikipedia，能随着维基百科的变化而发展。
l 它从维基百科中抽取出结构化数据，将数据变成Linked Data形式。
l 它的知识库采用了构建本体的形式对条目进行组织。 
l 具有开放API接口，使得机器也能读懂这些结构化数据。

DBpedia本体的体系结构主要有四类[8]： 
（1） part-of关系，表达概念之间部分和整体的关系 
（2） kind-of关系，表达概念之间的集成关系  
（3） instance-of关系，表达概念的实例和概念之间的关系 
（4） attribute-of关系，表达某个概念是另一个概念的属性
本文方法仅使用了“概念”与“类别”之间的关系，构造出类别树。比如，在维基百科中：
“贼鸥”所属分类：鸥形目 | 贼鸥科
“贼鸥科”所属分类：鸥形目
“鸥形目”所属分类：鸟类 |鸻形目
“帝企鹅”所属分类：IUCN近危物种 | 南极洲 | 企鹅科
“企鹅科”所属分类：鸟类 | 企鹅目 | 企鹅科
“企鹅目”所属分类：鸟类 | 企鹅目 | 企鹅科
最终可以得到需要一个如下的知识库：
贼鸥 -> 贼鸥科 ->鸥形目-> 鸟类 
帝企鹅 -> 企鹅科 -> 企鹅目 -> 鸟类

    在提取类别树的过程中,类别树的高度设置尤为重要,如果高度太高,则影响遍历速度,如果树高度设置太低,则降低匹配效果。
2.2 获得大小合适的类别树
如果我们构建的类别树太小，那么它的误差率会比较高。如果树太大，尽管用学习集检验获得的视误差率很小，但它的真误差率可能还是比较大。因此, 我们需要构建一颗大小适当的树，它的真误差率为最小。
决策树学习的目的是获得简洁而预测能力强的树。在树完全生长的时候有可能其预测能力反而会降低。为解决此问题，需要获得大小合适的树。一般来说，有两种方法。
方法之一是定义树停止生长的条件。常见的条件如下。
（1）最小划分实例数。当当前结点对应的数据子集的大小小于指定的最小划分实例数时，即使它们不属于同一类，也不再进行进一步划分。
（2）划分阈值。当使用的划分方法所得的值与其父结点的值的差小于指定的阈值时，则不再进一步划分。
（3）最大树深度。当进一步的划分将超过最大树深度的时候，停止划分。
方法之二是在生成完全的决策树后进行剪枝。通过对决策树的子树进行评估，若去掉某子树后整个决策树表现更好，则该子集将被剪枝。具体来说，在Breiman 的CART[9]中的做法如下：
（1）建树
由于决策类别树是由属性值划分数据集所形成的，需要定义由属性进行划分的度量，即根据该度量可以计算出对当前数据子集来说最佳的划分属性。
当选定了计算结点代价的模糊度函数，树的生长过程中，就是每次试图找一个最优分叉值，来划分结点中的样本，使得代价减小最大。模糊度函数是用来表示树结点 t 的模糊度或误差分割指标的，即为：
         （1）
这里，是一个决策集合，是该决策集中决策类的个数，≥0是第个决策类在决策集中的比例，且。
在CART算法构造的二叉树中，因为分叉而导致模糊度的改变量为：
           （2）
这里，t是正在分叉的结点；是结点t的模糊度；和分别是左右分支结点的模糊度；和分别是结点t中左右分叉样本的百分比。 对于每个内结点t的分叉，取t所有分叉可能方式中模糊度改变量最大的一个。对于别的结点重复同样的搜索过程。
（2）剪枝
以上算法生成的树规模很大，尽管视误差率很小，但它的真误差率可能还是比较大的。必须通过剪枝技术构建一棵真误差率小的树。运用一定的算法对这棵大树的树枝不断进行修剪。修剪过程中，将得到一列越来越小的树，形成一个修剪树序列，这一序列中的每一棵树与其它大小相同的子树比较，具有更小的视误差率[9]，可以说这一序列就是一个最佳的序列。基于最小代价复杂性原理修剪二叉树，修剪如下：
一般一棵树可以用 T 表示，而根节点为 t 的子树用 Tt表示，那么，剪枝后的子树 Tt3收缩成一个终结点 t3，剪枝后的树可表示为 T-Tt3，并有这样的关系 T-Tt3⊂T，它为 T 的子集。用表示树 T 中的终结点集，对应的终结点个数为。树 T 杂质指标的定义：
              (3)
为公式(3)中的树结点t的模糊度指标或结点t的拟合结点数据集的平方误差，误差指标为模糊度函数。
这里给出决策树剪枝原则，即代价复杂性测度：
        (4)
公式中需要说明为树的杂质指标代价和它的复杂度的线性组合。其中，是一个由于树的复杂性带来的代价的复杂度参数，为树T的终结点个数。
求树T的下一棵最小树：对于树T 的每个内结点t，我们需要求出下一棵树误分的惩罚因子的值，记为，这个值为当前树剪枝前后误差指标的变化量与终结点数目改变的比率：
           (5)
我们要选择的结点就是有最小的内结点。整个树的剪枝过程就是计算，然后，求最小，进而选择为下次剪枝对象。
对每一个给定的值，对应的其代价复杂性测度，总可以找到一个最小子树:
           (6)
当值增大时，一直保持最小，直到到达一个跳跃点，此时树成为新的最小树。
确定好最小树后，可求得其高度为。这里是最终叶结点的层数，是根结点的层数。
对本文的实例，按照上述算法可求得大小适当的树高为。
2.3 相似度算法
   传统的类别树相似度计算主要是字符直接查找法和向量夹角余弦计算法，然而这两种方法都过于简单，严重影响了相似性。因此本文在字符查找法的基础上，提出了基于DBpedia的模糊查询算法。
2.3.1 模糊查询算法（WIKIFQ）
假设按字或词的读音、含义、关联性等属性对搜索的内容进行分类，把N个样本共分成n 个类别(1<n<N)，这n 个类别分别为w1,w2,...,wn的样本集合，每类有标明类别的样本Ni个，i = 1,2,...,n，设样本的属性（例如，词意、词频等）有p个，则样本点的指标将可以构成一个p维特征空间，所有的样本点在这个p维特征空间里都有惟一的点与它对应。则对任何一个待识别的样本x =< a1(x),a2(x), ...,ap(x) >，其中ar(x)表示样本x 的第r 个属性。对于一待查询的实例x，首先在训练样本数据集中按照所定义距离选出最接近x 的k 个实例，并用x1, x2, ..., xk表示，设k1, k2, ..., kn分别是k个近邻中属于类w1, w2, ..., wn的样本数，若ki最大，实例x就属于wi类。
定义距离：设样本x =< a1(x),a2(x), ...,ap(x) >和样本y =< a1(y),a2(y), ...,ap(y) >，距离定义为：。
（1）查询内容分类
首先对待查询的样本进行适当分类。查询准则要求属于某一个类别的实例，到类内中心的距离越小越好，到类间中心距离越大越好。根据每类别的属性，求出其平均值作为类别中心vi，i = 1,2,...,n。设uik 是第k 个样本对第i 类的隶属度函数, 且, U={uik}。设是样本xk 和第i 类中心vi 的距离。m>1是模糊加权指数。通过定义类内距离和类间距离，使其满足类内距离越小越好，类间距离越大越好。
定义类内距离
     　　　　    　　 (7)
定义类间距离
     　　　　　　 (8)
综合式(7)和(8)，定义目标函数Jm (U , n)为
      　　　　　　 (9)
这里，Ui={uij}是对固定的i，U={uij}是对所有的i。
因为对于一个目标最终需要按一定的隶属度归属为某一类问题。所以目标函数满足一定的约束为:
,                    (10)
由目标函数，要求①定义的应与为反比关系，即关于是单调减函数。②关于模糊加权指数m是单调增函数。③因为为隶属度，所以。又因为要求各类别中必须至少包含一个样本，但样本不可能同属于一个类别，所以有成立。④同时满足式(10)。由①－④，可定义为：
      　　　　　　   (11)
可证明式(11)满足条件①－④。
在约束(10)下通过反复迭代求式(9)的极小值。确定最终的。
由，求各类别的中心vi如下：
              (12)
（2）字符匹配查询
对于一待查询的实例x，计算x与中心vi的距离，选出最接近x的k个字或词，并用x1, x2, ..., xk表示。定义序偶对< x, f (x) >， f (x)为实例x所属的类别：f (x): R→W，其中，R 为待查询的实例集，W为类别有限集合{w1, w2, ..., wn}，wi为划分查询内容的第i 种类型内容，n 为类别数。则f（x）的计算表示为：
，这时f (x)= ，则实例x属于类。也可以写为如下形式：，，这时x属于类， j = 1, 2, ..., n。其中，若a = b，则σ(a, b) = 1，否则σ(a, b) = 0。

2.3.2 模糊加权指数m的选择
对于式(11)，当m →1 时，式(11) 中的每一个有uij→0 或1, 当m = 1 时，没有加权; 当m →+ ∞时, 对于式(11) 中的每一个uij有uij→1/n, 此时的划分是最模糊的。可见, 指数m直接决定分类结果的模糊性。
对检索的内容进行分类，可利用关于BEZDEK, Lin Qing, Wei Meia等人研究的目标识别的模糊方法和算法[10-12]，分类的模糊度定义为
            　(13)
其中BEZDEK [10]
                      (14)
对于一个模糊决策问题，是对给定的一个模糊目标Gf 和一个模糊约束Cf的交集形成的，即。
本文查询关键字或词的这一决策问题的模糊目标为
          (15)
这里，U*为式(9)取极小值时确定的最终的集合。此外, 本算法在完成内容模糊分类的同时还要求内容的划分尽可能分明, 以便于正确区分每个样本的类属关系。因此, 这就给参数m 的选择加上了一个约束, 即所选取的值不要使模糊分类算法的分类结果太模糊。划分模糊度是评价模糊分类划分模糊性的良好量度。这样以来，参数m 优选的这一决策问题的模糊约束为
          (16)
当Gf 和Cf 作为模糊集处理时, 它们分别由其隶属函数来刻画。为了使模糊目标Gf和模糊约束Cf 的隶属函数具有相同的增减幅度, 可分别定义Gf 和Cf的隶属函数为
                 (17)
                         (18)
模糊决策的隶属度函数可表示为，最终的决策结果为满足的解。
于是, 最优加权指数m* 取为模糊目标和模糊约束所对应的模糊子集交集中的最大隶属度所对应的m 值, 由下式可求得:
             (19)
　  按式(19) 所得到的m* 将能保证, 既以较大的隶属度极小化分类目标函数, 又以较大的隶属度极小化分类的划分模糊度, 使模糊分类算法得到的模糊分类既能表达样本间的相近信息, 又能保证样本类分的明晰性, 因此, 也必然对应于好的模糊分类结果。

3. 实验
3.1 前期处理
1） 构建DbPedia数据库
    数据很大，如果直接放在文件中，无法索引检索，因此建立MYSQL数据库。从中文Wikipedia下载2013年11月份的XML dump文件，解压三个文件分别得到zhwiki-latest-categorylinks.sql、zhwiki-latest-pages.sql和zhwiki-latest-redirect.sql共计1.34GB，导入得到的DbPedia中文词条数据库，大约310.2万条page记录，31.5万category记录，773.6万条categorylinks记录。
2） 在极地标本资源共享平台的数据库中抽样N个词条[13]。
N=Random (50～100) ，N取50到100之间的一个随即函数。
3） 提取样本库的类别树，并形成权重矩正。单词条获取类别树代码如下[14,15]：

                         Fig1. Get category by entry name

Fig2. Get category list

4） 叠加模糊匹配算法取得相似度
实验中，选取模糊加权指数m=1.75.
5） 测试环境: 
CPU: 2.5GHZ X 2core 
   Memory: 4.0 GB 
   OS: Windows 7 64bit
3.2 实验结果
为了验证该算法的效率，将此算法和传统的逐字字符匹配算法，基于DBpedia语义算法进行比对[表1]，发现该算法比其它算法在语义分析上更加准确，就算是貌似南辕北辙的2个词也能找出之间的丝许关系。
表1 WIKIFQA与CCQ、WIKIQA的算法比较
词对
逐字字符匹配算法(CCQ)
DBpedia语义算法(WIKIQA)
基于DBpedia的模糊匹配算法( WIKIFQA)
贼鸥 - 贼欧
0.5000
0.0000
1.0000
贼鸥 - 企鹅
0.0000
0.2371
0.2371
平流层 - 对流层
0.6667
0.8899
0.8899
平流层 - 中间层
0.3333
0.8899
0.8899
平流层 - 行星边界层
0.3333
0.0000
0.0000
火山灰 - 硫酸盐
0.0000
0.0624
0.0624
气旋 - 干旱
0.0000
0.1346
0.1346
闪电 - 风暴
0.0000
0.3008
0.3008
霜 - 雾
0.0000
0.2961
0.2961
降雨 - 自然現象
0.0000
0.3968
0.3968
降雨 - 彩虹
0.0000
0.2353
0.2353
降雨 - 风暴
0.0000
0.3205
0.3205
风暴 - 龙卷风
0.5000
0.2121
0.2121
极光 - 彩虹
0.0000
0.3574
0.3574
沙漠 - 草原
0.0000
0.8819
0.8819
沙漠 - 沼泽
0.0000
0.5269
0.5269
沙漠 - 丘陵
0.0000
0.3971
0.3971
沙漠 - 岛屿
0.0000
0.3627
0.3627
沙漠 - 海洋
0.0000
0.3299
0.3299
子囊菌门 - 担子菌门
0.7500
0.5055
0.5055
木耳目 - 花耳目
0.6667
0.3557
0.6667
哲水蚤目 - 猛水蚤目
0.7500
0.9687
0.9687
哲水蚤目 - 劍水蚤目
0.7500
0.9687
0.9687
两栖动物 - 棘皮动物
0.5000
0.3328
0.5000
两栖动物 - 爬行动物
0.5000
0.6789
0.6789
软体动物 - 爬行动物
0.5000
0.3295
0.5000
软体动物 - 脊椎动物
0.5000
0.4775
0.5000
叶足动物 - 节肢动物
0.5000
0.6184
0.6184
有爪动物 - 缓步动物
0.5000
0.9848
0.9848
线形动物 - 节肢动物
0.5000
0.7044
0.7044
地质学 - 地球物理学
0.6667
0.5654
0.5654
地质学 - 气象学
0.3333
0.5320
0.5320
地质学 - 生物学
0.3333
0.4715
0.4715
地质学 - 文学
0.3333
0.3571
0.3571
水圈 - 岩石圈
0.5000
0.3436
0.3436
水圈 - 大气圈
0.5000
0.2353
0.2353
水圈 - 生物圈
0.5000
0.4883
0.4883
岩浆岩 - 沉积岩
0.6667
0.6360
0.6360
岩浆岩 - 变质岩
0.6667
0.4027
0.4027
岩浆岩 - 片麻岩
0.6667
0.4720
0.4720
变质岩 - 片麻岩
0.3333
0.8430
0.8430
岩浆岩 - 喷出岩
0.6667
0.7815
0.7815
岩浆岩 - 花岗岩
0.6667
0.5101
0.5101
叶绿素 - 光合色素
0.3333
0.5670
0.5670
叶绿素 - 光合作用
0.0000
0.3865
0.3865
二氧化碳 - 光合作用
0.0000
0.0300
0.0300
水 - 光合作用
0.0000
0.1077
0.1077
氧气 - 光合作用
0.0000
0.0604
0.0604
碳水化合物 - 光合作用
0.2000
0.2797
0.2797
冰斗 - 冰碛
0.5000
0.6373
0.6373
冰碛 - 冰川
0.5000
0.7061
0.7061
冰河 - 冰川
0.5000
0.9919
0.9919
冰盖 - 冰川
0.5000
0.8654
0.8654
山谷冰川 - 冰川
0.5000
0.6143
0.6143
石油 - 天然气
0.0000
0.4948
0.4948
石油 - 煤
0.0000
0.3162
0.3162
石油 - 风能
0.0000
0.1924
0.1924
石油 - 太阳能
0.0000
0.1272
0.1272
石油 - 能源
0.0000
0.4291
0.4291
石油 - 不可再生能源
0.0000
0.2837
0.2837
石油 - 清洁能源
0.0000
0.1494
0.1494
地震 - 海啸
0.0000
0.8564
0.8564
地震 - 滑坡
0.0000
0.5799
0.5799
地震 - 泥石流
0.0000
0.3734
0.3734
地震 - 火山
0.0000
0.3636
0.3636
地震 - 自然灾害
0.0000
0.7747
0.7747
中国南极长城站 - 长城站
0.4286
0.9940
0.9940
中国南极长城站 - 中国南极中山站
0.7143
0.5826
0.7143
中国南极长城站 - 中国南极昆仑站
0.7143
0.5199
0.7143
中国南极长城站 - 中国北极黄河站
0.5714
0.6437
0.6437
黄河站 - 北冰洋
0.0000
0.3268
0.3268
黄河站 - 南大洋
0.0000
0.1663
0.1663
长城站 - 南极洲
0.0000
0.1062
0.1062
长城站 - 北冰洋
0.0000
0.0890
0.0890

4 结论
    本文通过分析极地标本样品数据以及维基百科中文数据的特点,出了一种基于DBpedia的模糊查询算法，并给出了模糊算法特征值提取方法和语义匹配的算法实现。实验结果表明,与传统逐字字符匹配方法和DBpedia语义相似度算法相比,该首WIKIFQA方法能更高效，更准确的查找相似数据，提高数据匹配准确率。
参考文献：
1. Anagnostopoulos A, Becchetti L, Castillo C, et al. An optimization framework for query recommendation[C]//Proceedings of the third ACM international conference on Web search and data mining. ACM, 2010: 161-170. 
2. 程文芳, 张洁, 夏明一, 等. 极地标本资源共享平台系统设计与实现[J]. 极地研究, 2013, 25(2): 185-196.
3. Linden G, Smith B, York J. Amazon. com recommendations: Item-to-item collaborative filtering[J]. Internet Computing, IEEE, 2003, 7(1): 76-80.
4. 白如江, 于晓繁, 王效岳. 国内外主要本体库比较分析研究[J]. 现代图书情报技术, 2011, 1(7): 3-13.
5. Gabrilovich E, Markovitch S. Computing Semantic Relatedness Using Wikipedia-based Explicit Semantic Analysis[C]//IJCAI. 2007, 7: 1606-1611. 
6. 盛志超, 陶晓鹏. 基于维基百科的语义相似度计算方法[J]. 计算机工程, 2011, 37(7).
7. 刘军, 姚天昉. 基于 Wikipedia 的语义相关度计算[J]. Computer Engineering, 2010, 36(19).
8. 朝乐门, 张勇, 邢春晓. DBpedia 及其典型应用[J]. 现代图书情报技术, 2011, 3: 80-87.
9. Breiman L, Friedman J H, Oishen R A, et al. Classification and Regression Trees. Wadsworth, Inc. 1984.  
10. BEZDEK J C. Pattern Recognition with Fuzzy Objective Function Algorithms [M]. New York: Plenum Press, 1981.  
11. Lin Qing, Xiao-Ding Xu, Shi-Tong Wang. Fuzzy Particle Filter for Target Tracking. AASRI Procedia, Volume 3, 2012, Pages 191-196.
12. Wei Meia, Ying Xiao, Gang Wang. Target Classification Based on a Combination of Possibility and Probability likelihood in the Bayesian Framework. Procedia Engineering, Volume 29, 2012, Pages 9-14.
13. 麦范金, 李东普, 岳晓光. 基于双向匹配法和特征选择算法的中文分词技术研究[J]. 昆明理工大学学报 (自然科学版), 2011, 36(1): 47-51.
14. Martelli A, Ravenscroft A, Ascher D. Python cookbook[M]. O'Reilly, 2008.
15. Wiki API：http://zh.wikipedia.org/w/api.php

1

