随着大数据技术的发展和计算机硬件运算速度的不断提高，人工智能与机器学习技术得以飞速发展。在计算机视觉领域，基于神经网络与深度学习的机器学习算法可以帮助计算机模拟人脑理解图像和视频等多媒体信息。神经网络模型具有强大的拟合与回归学习能力，近年来在视频翻译问题上取得了突破性进展。连续手语视频翻译是计算机视觉领域的一个重要分支，在现实生活中有着重要的实用价值。手语是聋哑人日常生活中进行信息交流最自然的方式，连续手语视频翻译技术的发展为聋哑人的日常生活提供便利，实现听力障碍人群和正常人的自由沟通交流。手语翻译作为人机交互的一种方式，通过机器学习算法将聋哑人使用的连续手语动作翻译成对应的文字序列。
	手语视频自动翻译属于广义的序列到序列问题，其难点在于视频中视觉信息的识别，不仅要考虑当前时刻的图像帧信息，同时关系到连续帧之间复杂的动态变化关系。本文运用循环神经网络算法，使用编码解码结构和级联时序分类的实时翻译结构，对手语翻译问题进行时序建模。在编码解码模型中，提出时序池化操作，嵌入在翻译系统的分层编码器中，有效解决了连续视频数据的信息冗余问题，使得翻译效率和效果均得到显著提升。由于编码解码模型在长时手语视频翻译上存在梯度消失问题，本文随后提出了一种端对端的基于级联时序分类优化方法的双路并行学习模型，其中，在卷积神经网络和循环神经网络并行的双路网络结构中，卷积神经网络模块专注于二维图像上的局部感知，循环神经网络侧重于连续动作的时序建模，突出了全局序列在时间维度上传递的内在关系。最后将两个模块输出的得分矩阵进行融合，结合级联时序分类优化方法，端对端地输出翻译语句序列。该方法能够同时有效兼顾视频中长时和短时的时空视觉信息，在长时手语视频翻译任务中取得良好效果。
