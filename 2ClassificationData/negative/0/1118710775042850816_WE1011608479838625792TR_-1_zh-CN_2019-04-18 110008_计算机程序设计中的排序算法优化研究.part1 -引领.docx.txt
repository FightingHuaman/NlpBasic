排序算法作为经典算法在各类软件开发中都有非常高的使用频率，甚至成为近年来较为火热的聚类分析、机器学习、推荐算法等人工智能领域的基础算法之一。[1-4]C.A.R.Hoare在1960年提出的快速排序甚至被称为20世纪科技领域十大算法之一[5]，Marcos Otero在2015年5月27日发表的博客上指出归并排序、快速排序和堆排序是真正统治我们世界的十大算法之一。因此说排序算法在计算机相关领域的发展中起着举足轻重的作用。
排序算法主要有基于比较的排序和非基于比较的排序两个类别，由于非基于比较的排序应用场景较少且具有较多的限制，因此本文中对排序算法现状的描述均是指基于比较的排序算法。
从排序问题提出至今，研究人员和工程人员对排序算法进行了全方位的改进，但是其理论时间复杂度一直停滞在O(NlogN)[6]。随着大数据和机器学习的兴起，计算机需要处理的数据量也越来越大，已有的排序算法难以适应。目前来说对排序算法的优化仅停留在实际运行时间的减少，并没有对理论时间和最坏时间进行进一步优化。目前来说，快速排序和归并排序作为应用较为广泛的排序算法之一，在众多学者和工程师的研究和优化后可以使得大部分的排序过程的时间消耗略微低于理论时间复杂度O(NlogN)，但是效果并不是很理想，没有达到质的改变。
本文利用基于机器学习模型提出了一种新的排序算法：
1、 利用TensorFlow Lattice训练数据得到数据分布模型。TensorFlow Lattice能定义模型的单调性和取值范围，这使得训练出的模型在数学上符合分布函数的性质，相比于传统神经网络能更好的描述整个数据的分布。
2、 为了提高构建数据分布模型的效率，我们利用数据的频率分布图来对数据进行采样并构建分布模型的训练数据集。这种方法能显著降低训练集的规模，相比于简单随机采样这种方法的采样结果更能代表整体。
3、 。。。。。。
我们使用六组数据将本文提出的排序算法和已有的快速排序、归并排序和堆排序进行对照实验。这六组数据包含五组随机生成的数据和一组实际测量采集的雷达相位数据，数据规模从100万到600万不等。实验证明，本文提出的排序算法运行效率更高。
本文其他部分结构如下：第二节回顾了当前已有的排序算法和模型构建方式；第三节描述了整个排序算法是如何工作的、为何这样、实现细节以及时间复杂度分析；第四节描述了几个实验以评估本文提出的排序算法；第五节对本文工作进行总结和对今后工作进行展望。
2、
2.1、排序算法
通过一定的方法将杂乱无章的数据元素按关键字顺序排列的过程叫做排序，完成这个过程的方法叫做排序算法。
解决排序问题的排序算法又可以分为基于比较的排序和非基于比较的排序。非基于比较的排序算法需要结合数据的具体结构和相关特点来进行特定的设计。Omar, Yasser M.K.等[7]提出了一种非基于比较的排序算法，即双散列排序算法，这种算法用散列函数收集了数据的分布情况后再利用散列函数为元素建立映射最后再对数据进行处理和排序。这种类型的排序算法虽然具有较高的效率，但是难以适应通用数据。由于基于比较的排序算法具备良好的通用性，国内外有非常多的学者对这类排序算法进行了研究和优化[8-10]。Vignesh R等[11]提出了一种用归并排序增强的原地排序算法，该算法先对序列中有序元素进行划分在利用归并排序的思想进行合并。Tim Sort作为内嵌在Java和Python中的排序算法是应用较为广泛的，它考虑到实际数据并不是完全无序的，因此它将数据中有序的子序列提取出来进行预处理达到优化排序时间的目的[12]。但是，以上这些软件层次上的改进并没有取得质变的效果，所以需要一种更快速的排序算法。
目前除了传统的对排序进行优化，还有研究人员利用并行计算、图形处理单元、分布式计算等对排序算法进行优化。Marszalek Zbigniew[13,14]利用并行计算对归并排序算法和快速排序算法进行了优化处理，处理器越多排序效率越高。但是由于存在其他因素的影响，这种优化有一定的瓶颈。Faujdar Neetu等[15]改进了冒泡排序算法并部署在GPU上，取得了较好的优化效果，最优情况的时间复杂度达到了O(1)。Pang Na等[16]人结合快速排序和归并排序的思想对云计算数据进行分类和整合，提出了一种基于云计算大规模数据排序算法。这些改进的排序算法要么需要大量的计算资源，要么需要额外的计算设备，有一定的使用门槛，推广起来较为困难。
除了从算法层面进行考虑，还有研究人员利用硬件电路完成了数据的排序。Kim Youngil等[17]、Abdel-Hafeez Saleh等[18]和Zhao Fangzhou等[19]都对从硬件实现排序功能做了一定研究。但是由于使用成本、后期维护和规模限制等一系列问题，利用硬件实现的排序功能难以得到广泛推广和使用。
随着机器学习的不断发展和成熟，机器学习的某些领域已经取得了较大的成就，但是利用机器学习相关理论对传统数据结构和算法进行优化的研究还比较少。
2.2、数据分布模型研究现状
每一组数据都可以用一个模型来描述数据的分布情况，这样的模型被称为数据分布模型。通过数据分布模型获取待排元素在有序数组中的位置来完成排序操作，是一种新颖的排序方式。
分布模型是由分布函数来表示的一种模型，分布函数既可以是基本函数也可以是不能用解析式表达的抽象函数。目前常见的分布有均匀分布、正态分布、指数分布、二项分布等都是能用解析式表达的分布函数，但是在实际的数据中几乎没有数据是完全符合已知的分布模型且难以用解析式表示。因此通过一般编码的方式难以获得数据的分布情况，可以通过机器学习相关理论和工具来完成对分布函数的拟合和估算。
机器学习主要应用方向有分类器和回归拟合，对数据分布进行建模主要就是对分布函数进行回归拟合。不少研究人员对回归拟合的优化和应用做了研究。Miao Shun等[20]提出了一种利用卷积神经网络对二维和三维数据的回归，所提出的方法具有3种潜在的临床应用，并已被定量评价，结果表明其有显著的优势。Enayatollahi Iman等[21]利用神经网络和多元回归分析分别对露天矿中岩石破碎情况进行了预测，结果表明，神经网络构造的回归模型远远优于多元回归分析。Postnikov Eugene B.等[22] 针对含有噪声数据的线性拟合问题进行了研究，得到了一种能在含有较多噪声数据的情况下提供稳定的回归方法。Paul Chinmoy等[23]比较了回归分析和基于聚类的神经网络方法，他们将所提出的聚类算法与神经网络相结合，可以模拟地控制离群值和未知的函数形式，有效的提升训练效率和精度。Kicsiny Richard等[24]在多元线性回归的基础上，提出了一种具备通用性和易用性的线性回归模型，这种模型能够更加精确的描述太阳能电池运作时的瞬态过程。Zhao Zijing等[25] 提出了一种新的基于深度学习的更稳定、更精确的眼周识别结构，该模型采用注意力模型来强调眼周图像中的重要区域，这种模型的识别能力明显优于其他已有模型。
