
 
基于数据标签化的混合存储架构下数据调度机制探索

摘   要
大数据是当前学术界和工业界关注的热点，开展高效快速的大数据分析是其中的重要基础内容，是大数据应用的核心基础。由于DRAM的扩展性较差，大数据分析和相关应用性能难以得到很好的提升。DRAM/NVM混合存储架构具有非易失性、存储密度高等优势，为大数据分析带来了优化的契机。因为任务本身对数据有依赖性且不对数据进行修改，所以在混合存储架构背景下如果能在存储系统上进行合理的数据部署，则可以为大数据解决操作时延的问题提供可能。
本文以优化大数据高延时的问题为目标，对磁盘和混合内存架构之间的数据部署和调度进行了研究。首先简单介绍了混合存储系统的相关背景和工作。其次通过问题分析探讨了磁盘和NVM间数据迁移的标准，并进行合理的数据部署。接下来提出基于标签化的数据调度算法，同时根据任务排队等待处理的问题研究了任务调度的优先性。最后在实验中通过计算任务调度数据的总时间验证了标签化的有效性，提高了任务执行的效率。
关键词：标签化，混合存储架构，磁盘，数据调度


第一章  引  言
1.1  研究背景
随着信息行业和互联网技术的不断发展，金融公司、搜索引擎、社交网络等各个领域都出现了数据大规模的增长。这些数据的数据量达到了GB级别、TB级别甚至是PB级别，因此我们将这些数据称为大数据。最早提出“大数据”时代到来的是全球知名咨询公司麦肯锡，麦肯锡称：“数据，已经渗透到当今每一个行业和业务职能领域，成为重要的生产因素。人们对于海量数据的挖掘和运用，预示着新一波生产率增长和消费者盈余浪潮的到来。”[1]大数据具有数据量巨大、数据种类多、生成速度快但数据价值密度低的特点[2]。大数据应用就是通过利用数据分析和数据挖掘等方法，提取大数据中有价值的信息，为用户或者企业提供决策参考的过程。
在传统的冯·诺依曼结构中，CPU进行任务处理所需要的数据是从磁盘中先迁移到内存中，然后CPU再从内存中读取数据的。由于CPU的处理速率远远高于I/O接口的处理速率，当CPU需要在大量的资源或数据上执行一些简单的指令时，因为I/O接口流量与CPU工作效率相差太大，会使计算机运行的整体效率受到严重的限制，从而带来大数据处理高延时的问题。对于操作时延的瓶颈，目前主流的解决方法是尽量扩大内存的存储空间，将需要处理的数据尽可能多的放置在内存中。这样会带来两方面的问题：1、如今的主存系统都以动态随机存取存储器（Dynamic Random Access Memory，DRAM）为核心构成内存来管理和存储大数据，由于DRAM用电容的充放电来表示“0”和“1”，电容因漏电会导致信息的丢失，所以需要周期性的刷新DRAM来保存DRAM中的数据，即DRAM是易失性的，存储在DRAM上的数据有丢失的风险。同时周期性的刷新操作给计算机系统带来了额外的时间开销。2、由于DRAM的可扩展性受限，导致内存的存储容量得不到很好的提升，无法对大数据进行高效的存储和处理。
新型非易失性存储器（Non-volatile Memory，NVM）具有非易失性、高存储密度、低能耗、良好的扩展性等满足大数据存储技术需求的优点，为解决大数据高操作延时的问题提供了优化的契机。但是NVM也存在读写性能不对称、耐久度有限等问题。如果用NVM完全取代DRAM去构成计算系统的主存，也会对计算系统的性能、寿命等方面造成一定的影响。  目前学术界采用NVM和DRAM组成的混合存储架构来解决上述存在的问题。DRAM/NVM混合存储架构不仅利用了NVM非易失性、高存储密度和DRAM写操作速度快的优势，同时也一定程度上避免了NVM读写性能不对称和耐久度有限的缺陷，较好的满足了大数据的应用需求。例如，英特尔将其和镁光联合开发的3D Xpoint非易失性存储方案运用到了DIMM（Dual Inline Memory Modules，双列直插式存储模块）内存插槽中，推出了全新的傲腾内存模块（Optane DC Persistent Memory），该产品的单条容量最高可达512GB，支持部署高达3TB的非易失性存储，且能够快速吞吐巨量的数据。[3]
但是由于NVM存在的一些缺陷如写性能较差、寿命不长等，混合存储架构依然面临着挑战。因为混合存储架构存在的瓶颈主要是由NVM写性能和耐久度的缺陷所引起的，所以目前学术界的研究思路普遍是将写操作尽可能多的分布到DRAM上，将读操作尽可能的分布到NVM上。因此学术界的研究热点大多集中在内存管理部分，即NVM和DRAM内存之间的数据迁移，从减少NVM的写操作方面入手以达到减少操作时延、提高大数据处理效率的优化效果。但是就应用层面来讲，许多企业或组织更多的是进行大数据的分析与挖掘操作，从而为接下来的工作提供参考。对于大数据分析任务本身而言，其任务所用到的数据不需要进行更新，只需要将数据调入CPU进行处理便可。因为任务对数据有依赖性，且不对数据进行修改，所以如果可以在任务处理之前，将任务处理中所需要的数据存储在内存里或者提前从磁盘中迁移到内存里，进行数据预取和预部署，则会大大缩短数据的读取时间，从而缩小CPU和I/O口之间工作效率的差距，减少大数据处理的延迟时间。又因为磁盘和NVM的性能有差异，在两者上进行不同的数据部署会带来计算机系统处理效率的差别，所以我们希望在进行磁盘和内存间的数据调度过程中能有所依据，即考虑将什么样的数据部署在磁盘中，将什么样的数据迁移到内存中从而能带来操作时延问题的优化效果。基于此问题，我们提出了将数据标签化的解决方法，就是给任务所需要处理的数据加上标签，根据这些标签来进行数据部署和任务调度。
1.2  本文主要内容
本文首先阐述了该毕业设计课题的研究背景，包括大数据、新型非易失性存储器、混合存储系统的相关内容，详细描述了大数据的特点及在传统存储架构下存在的瓶颈，新型非易失性存储器的优缺点以及混合存储架构的产生背景及优势，并且根据大数据分析任务的特点提出了标签化的概念。然后详细介绍了当前NVM/DRAM混合存储系统和HDD/SSD混合磁盘的发展进程与研究现状，主要是不同存储介质之间的数据交换算法的介绍，并根据当前的研究热点提出关注磁盘与NVM之间数据交换的观点。
通过仔细研究已有的数据调度算法和任务调度算法，并分析数据部署与任务执行的关系，分别提出了基于标签化的数据调度算法和基于最高紧迫服务比优先的任务调度方式。
（1）基于标签化的数据调度算法。设定所有的数据原本均存储在磁盘中，在CPU处理任务之前，根据标签化的定义给数据加上标签，然后将具有标签的数据依情况迁移到NVM中。
（2）基于最高紧迫服务比优先的任务调度方式。当待处理的任务达到服务器在排队等待处理时，根据任务的紧迫度和服务时间计算该任务的紧迫服务比，挑选紧迫服务比最高的任务投入系统进行处理。
最后通过Python编程语言来实现以上数据调度算法和任务调度方式，在任务调度方式的基础上通过是否加入标签化数据部署算法的结果对比，以任务需要的数据调度的总时间为衡量标准，来验证标签化的性能。最终实验结果表明，随着任务数和任务访问的数据量增加，加入标签化数据部署算法的总时间小于没有加入标签化数据部署算法的总时间且两者差距越来越大，从而验证了标签化的有效性。
1.3  本文组织安排
本文的组织结构如下。
第一章为引言。首先介绍了本文的研究背景，包括大数据的特点和当前存在的瓶颈、新型非易失性存储器的优缺点、混合存储系统的相关内容，并且根据大数据分析任务的特点提出了标签化的概念。最后简单的介绍了本文的主要研究内容和工作，并对文章的组织安排进行了说明。
第二章为存储器的研究现状。本章详细介绍了当前NVM/DRAM混合存储系统和HDD/SSD混合磁盘的发展进程与研究现状，简要的分析了当前的研究热点方向以及相关工作存在的不足之处，并根据对研究现状的分析提出关注磁盘与NVM之间数据交换的观点。
第三章为标签化模型的建立。本章首先对本文研究的数据部署和任务调度问题做了详细的描述和具体的分析，然后引出建立标签的思想。接着提出了标签的分类和定义，建立了标签化的模型。最后基于已经确定的标签提出磁盘和NVM上的数据部署策略，并且对本章内容进行总结。
第四章为数据调度算法和任务调度方式。本章介绍了本文提出的数据调度算法和任务调度方式——标签化数据调度算法和基于最高紧迫服务比优先的任务调度方式，包括基本思想、流程图、伪代码描述和编程的实现，并通过举例简单分析了两者的优化性。同时也介绍了操作系统常用的调度算法,包括先来先服务调度算法、短作业优先调度算法、最短剩余时间优先调度算法、高响应比优先调度算法。最后对本章内容进行了总结。
第五章为标签化有效性验证实验。本章首先介绍了实验的设计思路，然后在三种数据部署情况下——标签化数据部署、数据均部署在磁盘、某种特定数据部署方式分别计算任务读取数据的总时间，进行对比来验证标签化的有效性。最后对实验的结果进行分析，并总结了本章的主要内容。
第六章为总结与展望。在论文的最后一章，对全文进行一个严谨且客观的总结，并指出本文的优点和不足之处，并在此基础上，提出需要进行更深入的工作研究，对未来的研究方向进行了合理的展望。






















第二章  存储器的研究现状
2.1  混合存储架构的研究现状及分析
近年来，学术界对于混合存储架构的研究主要集中在NVM和DRAM的数据交换方面，主要以减少NVM上的写操作为优化目标。为了提升NVM/DRAM混合存储系统性能，减少计算机系统主存储器中的能量消耗，S Lee等人提出了基于脏数据位和写频繁度的时钟算法（CLOCK with Dirty bits and Write Frequency，CLOCK-DWF）[4]，通过数据被访问的频繁度与写访问请求的历史记录，准确地估计数据未来的冷热度；为了减少NVM上的写操作给NVM/DRAM混合存储系统带来的负面影响，Minho Lee等人提出了迁移优化的页面替换时钟算法[5]（Migration-optimized CLOCK,M-CLOCK），根据参考位和脏位决定数据是否需要迁移,并将读取密集型的页面迁移到NVM中来保证DRAM中有可用的空间，还利用了一个懒惰迁移（lazy migration）来解决迁移冲突的问题； Ramos L等人提出了一种基于排列的页面放置方法（rank-based page placement，RaPP）[6]，根据页面不同的访问频率和写操作的强度有效的排列页面，将排名靠前的页面迁移到DRAM中从而提高混合存储系统的性能；为了最大限度的避免无用的迁移，降低混合存储系统在应用环境下的能源消耗，Dong-Jae Shin等人提出了自适应的页面组管理（adaptive page grouping，APG）[7]，通过将热度相近的页面聚类在一起，并设置阀值，将页面组划分为冷热组； Dhiman等人基于DRAM/NVM平行混合存储结构提出根据写次数定义热数据的数据迁移方法[8]，Kim D 等人在此基础上提出了动态定义热数据的方法[9]。
为了减少NVM上的写操作并且保持稳定的时间性能，Z Wu等人提出了基于访问形式预测的LRU算法（Access-Pattern-prediction-based LRU， APP-LRU）[10]，通过元数据表记录页面的访问历史检测内存中每个页面的读写强度以区分页面的读写倾向；为了在减少NVM上的写操作的同时，保证系统的命中率，确保系统在应用中的性能，K Chen等人提出了保持命中率的LRU替换算法（Maintain-hit-ratio LRU，MHR-LRU）[11]，通过LRU链表管理读写倾向划分后按照使用时间排序的页面，将最近更新的页面保存在DRAM中；为了克服NVM耐久度不高的困难，Seok等人提出的基于预测和迁移的页面置换算法（LRU with prediction and migration， LRU-WPAM）[12]，对每个页面进行监控，通过公式计算每个页面代表其读写倾向性的权值来保证读访问的页面存储在NVM中；为了在不需要进行硬件改造的基础上减少页面调度时对NVM的写操作，提高NVM的寿命，清华大学计算机系刘巍提出一种新的基于NVM和DRAM混合内存构架的页面调度算法 CLOCK-S[13]，该算法引入内存页属性参数，根据经典算法中的脏位和页面的属性参数判断该页面的读写性以及相邻页的空间局部性,将页面部署在不同的存储介质上。
根据上文对于DRAM/NVM混合存储架构研究现状的陈述，可以看出学术界对于NVM/DRAM混合存储系统的研究主要集中在优化NVM和DRAM间的页面迁移算法方面。从考虑NVM读写不对称缺陷入手，着重关注什么情况下做出迁移页面的操作以及如何进行页面的迁移和置换，从而达到减少NVM上写操作、延长NVM寿命和提高命中率的优化目标。
2.2  闪存与磁盘存储的研究现状及分析
目前对于磁盘的研究主要有两种观点[14]：一种观点是将闪存作为内存与磁盘之间的缓存，对数据进行预读写。另一种观点是将闪存作为二级存储介质，即闪存与磁盘地位一致，人为或者自动地将不同特点的数据放到磁盘或闪存里。其中主要的研究方向为HDD（Hard Disk Drive，硬盘驱动器）和SSD（Solid State Drive，固态硬盘）混合存储系统。为了实现高磁盘效率，Zhang等人提出了iTransformer[15]，它利用一个小型SSD来安排磁盘上数据的请求，它在将脏数据写回磁盘并将一批数据预先存储到SSD中之前缓冲脏数据。为了提高I / O性能，Kim等人提出将闪存用作混合存储系统的非易失性缓存[16]，并设计了智能固定策略。Yoon等人使用完全关联扇区转换（FAST）方法来管理混合存储系统[17]，在这个存储系统中，闪存被用作缓冲空间。为了提高I / O性能并降低磁盘功耗，Bisson等人利用闪存作为混合存储系统的缓冲区[18]。Hsu等人提出将NAND闪存用作混合存储系统的二级缓存[19]，以便存储经常使用的程序。Ryu等人提出了一种数据预取方案[20]，该方案将一段数据预取到闪存中以降低HDD / SSD混合磁盘驱动器的磁盘能耗。Shim等人提出采用闪存来缓存写请求[21]。Lv等基于闪存的混合存储系统提出了一个名为HAT的热敏感缓冲区管理[22][23]，它采用SSD作为主存储器和硬盘之间的数据缓冲区。Han等人利用SSD作为SSD的缓冲区[24]，并提出了一种新的SSD缓存方案，将数据块从HDD迁移到SSD。为了解决混合存储系统中由在缓存中有脏版本的数据带来的不必要的迁移操作问题，Mingwei Lin等人提出了基于“垂死”数据的顺序迁移数据方案[25]，该方案倾向于选择不包含或者包含最少的“垂死”数据的块进行迁移，将“垂死”数据和实时的数据区分开来，避免不必要的迁移。
上文阐明了当前研究闪存和磁盘存储的相关工作，其热点是DRAM、闪存和磁盘间混合存储方面。学术界提出的两种混合结构——闪存和磁盘平行结构和闪存作为磁盘的缓存结构是目前研究的主流内容。许多文献以解决HDD/SSD混合磁盘当前所存在的瓶颈为目的，提出对应的管理策略，以达到降低磁盘功耗，提高I/O口性能，减少不必要的迁移操作的效果。
综上所述，学术界针对主存管理和混合磁盘的研究在一定程度上提高了存储器的性能，然而，在大数据分析时，只考虑混合内存或者混合外存内部的数据交换是无法满足当前大数据处理低延时的需求的。为了提高任务的处理速率，内外存间的数据调度也至关重要。而磁盘和混合内存的存储介质不同，其性能各有优势，数据部署在不同的存储器上所带来的影响也是有差别的。如何根据存储器特性的差异部署数据以及内外存间的数据迁移依靠什么标准也是亟待解决的问题。由于传统的计算机内外存间的数据迁移是基于磁盘和DRAM之间的，相关的研究比较全面且深入，所以本文着重于关注磁盘和NVM间的数据调度方案。基于上述分析，本文提出了标签化的数据调度算法，为磁盘和NVM间的数据迁移提供了标准，同时提出了针对大数据分析任务的最高紧迫服务比优先的调度方式，并设计模拟实验进行标签化的有效性验证。

















第三章  标签化模型的建立
3.1  数据部署及任务调度问题描述
任务的处理依赖于数据，同时也不对数据进行更改。因为数据可以存储在磁盘或者内存中，所以当任务需要访问数据时，会出现两种情况：（1）任务直接从内存中调用所需要的数据；（2）任务从磁盘中读取数据。当任务访问磁盘中的数据时，并不是直接读取的，而是经历了先将数据迁移到内存，再从内存读取这样一个过程的。可以明显看出，任务从磁盘中访问数据会消耗更多的时间，并且由于I/O口流量小，更加剧了任务处理的延时时间。我们希望任务尽可能多的从内存中读取数据，即存储在内存中的数据越多越好，但是内存的容量有限，将所有的数据都部署在内存中是不可能的。因此我们需要寻找合理的数据部署和数据迁移方式，可以尽量减少任务读取数据的时间，即考虑将什么样的数据部署在内存中，将什么样的数据部署在磁盘中，什么时候进行数据迁移，最终使任务访问数据的时间最小化，从而减少任务处理延迟的时间。数据部署的问题模型如下图3.1所示。

图3.1 数据部署问题模型
对于任务本身而言，不同的任务具有不同的特性，如到达时间、开始时间、服务时间、截止时间等。当一系列任务已经到达服务器后，对单处理器的系统来说，通常有多个不同的任务在排队等待处理，所以会有很多的任务相互竞争计算机的资源。任务在服务器中的状态有三种：运行态、等待态和就绪态。其状态转换如下图3.2所示。当任务还需要等待I/O设备或者所需要的数据还没有到达该任务的情况下，任务处于等待状态；当任务拥有除了CPU之外的其他所有需要的资源时，该任务可以执行，处于就绪状态，调度程序从就绪队列中选择下一个需要执行的任务赋予CPU资源开始处理；当任务在CPU中执行时便处于运行状态。对于单处理器系统而言，同一时刻，CPU只能对一个任务进行处理。当就绪队列中存在很多任务等待分配处理器资源时，我们就需要考虑根据什么标准来决定任务开始执行的时间，使得长任务、短任务、紧急任务等能被合理的安排运行，即图3.3中的调度部分。

图3.2 任务状态变迁图


图3.3 任务队列管理
3.2  数据部署及任务调度问题分析
任务A的处理需要调动m个数据，假设CPU从内存中读取数据的时间为。任务从磁盘中读取数据的总时间会随着存储在磁盘中的数据量增加而增加，即，其中为常数，为任务需要的数据存储在磁盘中的个数。若m个数据都需要从磁盘迁移到内存再调入CPU进行处理，则总时间为，这样会消耗大量的时间。如果根据数据的访问特点将部分数据存储在内存中或者提前从磁盘中调入内存，则节省了磁盘到内存的数据迁移时间，缩短CPU处理速度和存储器数据调度速度的差距，这个优化目标我们用任务读取所有需要的数据的总时间makespan来衡量。因此我们的问题是找到合适的标签化方法和恰当的混合内存和磁盘间的数据迁移方式，使得makespan最小化。
为了将该问题描述的更加清楚，我们举出下列例子来进一步说明。

图3.4 任务访问对应的数据

表3.1 任务访问对应的数据
任务
访问的数据
S1
d1、d2、d4
S2
d1、d3、d5
S3
d4、d5、d6
例子中有3个任务和6个数据，每个任务所需要访问的数据如图3.4和表3.1所示。我们设定在这6个数据中，d4和d6存储于混合内存中，d1、d2、d3、d5存储于磁盘中，并确定任务从内存中读取每个数据的时间为1，从磁盘中读取每个数据的时间为1.5，则任务S1所需要的时间为，任务S2所需要的时间为，任务S3所需要的时间为，假设系统执行完当前任务才可以执行下一个任务，则最终所有任务读取数据的总时间makespan为12。
由上述分析可以看出，当任务访问内存中的数据量越大时，其所需要的时间越少，即要使makespan最小化，就要尽可能的将数据部署在混合内存中或者在任务执行之前提前将数据迁移到内存中，减少数据从磁盘调度到内存的时间。但是受限于内存的容量，不可能将所有数据都放置在混合内存中，所以我们接下来的算法就要针对如何在有限的内存空间中，通过特定的标准进行合理的数据部署和数据迁移，使任务读取数据时尽可能的从内存中访问，缩短任务处理的时间。
对于任务调度部分，在单处理器系统中，我们设定有m个任务在就绪队列中排队等待CPU处理。由于CPU同一时间只能处理一个任务，所以需要给这m个任务排序，安排合理的处理顺序，即定义每个任务处理的优先度。因为所有任务均有紧急度、执行时间、到达时间、等待时间等特性参数，所以我们初步设想根据这些特性参数来定义每个任务的优先度。所以我们接下来考虑的重点在于寻找合适的优先度设置方法，使得任务调度能有所依据并在合理的时间被调入CPU进行处理。
3.3  标签化的分类和定义
对于上述问题分析中提到的特定的标准，本文提出了标签化的概念。所谓标签化，即是给数据制定特殊的标签，对数据进行划分，从而针对不同的标签进行数据管理和迁移，提升任务执行的效率。所以首先需要给出标签的种类和具体的定义。
本文根据大数据应用背景下任务访问数据的特点提出了以下五种标签，并通过设置给定值进行具体的标签定义。
（1）冷热数据划分：该标签根据数据的访问频率和最近访问间隔来确定数据的冷热性，表征该数据被任务所需要的程度，其值等于该数据在任务中被访问的次数，即该数据读写次数之和。如果在某段时间内，数据在以该数据为处理对象的任务中被访问的总次数超过一定的阈值，我们认为这段时间内该数据的标签为“热”。如果某段时间内该数据被访问的次数低于一定的阈值，我们认为该数据的标签为“冷”。 
（2）读写倾向划分：该标签根据数据读写操作的多少进行划分，表征该数据读写倾向的不同，其值等于该数据读写次数的差值。如果在某段时间内，该数据的读次数高于写次数并且差值超过一定阈值的，我们认为该数据的标签为“读倾向”，用正值表示，绝对值越大读倾向越大，反之如果该数据的写次数高于读次数且差值超过一定阈值的，我们认为该页面为“写倾向”，用负值表示，绝对值越大写倾向越大。其余页面我们将其标记为“无明显倾向”。 
（3）按生存期划分：该标签根据数据在系统中的生存时间来划分，如用完即删数据、周期性读取数据、永久存放数据等，表征该数据在系统中存放的特征，其值用表示。如果该数据在系统中永久存放，则令；如果该数据是用完即删的数据则令；如果该数据是周期性读写的数据，则用其周期值表示，即（为该数据周期性读写的周期值）。 
（4）按稀有度划分：该标签根据数据的备份副本个数来划分，评估当前数据副本的稀有度，其值等于该数据的副本个数。为了保证数据不被丢失，数据中心要保证所有的有效数据至少有一个副本。如果该数据有2个副本，则稀有度为2。一般数据设置为3个副本，则稀有度为3。稀有度值越低，表明该数据的副本备份越少，数据越重要，需要首先被恢复。该标签对数据的恢复可能会有所帮助。 
（5）特定场合的应用标签：这部分的标签一般由上层应用或者公司给出。比如纽约大学网站上公布了数据分类表，按照其机密程度划分，将数据分为四种：restrict, protected, confidential, public机密性递减的四种。针对很多数据挖掘算法如Aprior算法只能处理离散型数据的情况，可将数据分为连续、离散两类。对于有些数据每天在更新而有些数据一周或者一个月、一年才更新的情况，可以按照其更新频率来划分。对于上层应用给数据进行重要性的定义，我们也可以将数据按照重要性划分后再进行管理存储。
3.3  基于标签化的数据部署策略
在上一节中，我们介绍了数据在磁盘和NVM间迁移的依据——标签化，根据数据本身所具有的一些特征如读写操作次数，生存周期，副本备份个数等制作标签并给出了详细的定义。由于磁盘和NVM的存储介质不同，数据存储在不同介质上的性能差异较大，所以在本节中，我们将研究已经具有标签的数据在磁盘和NVM上的部署策略，从而使存储器的性能达到较好的优化效果。
针对不同的数据标签和NVM、磁盘的性能差异，我们提出了相应的数据管理方案。由于稀有度标签针对的是数据备份问题，特定应用场景下的标签不具有一般性，而前三个标签——冷热数据标签、读写倾向标签和生存期标签与操作时延问题息息相关，所以在这里我们考虑基于这三个标签划分下的数据部署问题。
（1）对于冷热标签：如果该数据被标记为“热数据”，表明该数据经常被CPU访问，我们将其存储在NVM中，这样节省了数据从磁盘被读取到内存中的时间，从而减小了数据处理操作的延时。如果该数据为“冷数据”，表明该数据不经常被访问，则将其存储在磁盘中，等需要读取该数据的时候再从磁盘迁入到内存中。
（2）对于读写倾向标签：由于NVM的读性能较好，写性能较差，而磁盘的写性能又高于NVM，所以将具有“读倾向”的数据存储在NVM上，将具有“写倾向”的数据存储在磁盘中。
（3）对于生存期标签：当数据的标签为“永久存放”时，表明该数据永久存储在系统中，因为NVM具有非易失性，所以将该类型的数据存储在NVM上方便读取。当数据的标签为“用完即删”时，表明该数据为流式数据，在CPU读取之后便从内存中删去，不需要将其存储在非易失性的NVM中占用内存空间资源，所以将该数据存储在磁盘中。当数据的标签为“周期性读写”时，为节约NVM中的存储空间，我们将该数据先保留在磁盘中，在下一个读写周期到来之前，将数据提前从磁盘迁移到NVM中进行数据的预部署。
3.4  本章小结
本章主要进行了数据部署和任务调度问题的描述，并针对该问题进行了详细的分析。然后提出标签化的概念、分类和具体的数值定义。最终基于标签的分类提出了NVM和磁盘间的数据部署方式，为接下来本文提出的算法奠定基础。 















第四章  数据调度算法和任务调度方式
本文基于上述的问题分析和建立的标签化模型提出了标签化数据调度算法和基于最高紧迫服务比优先的任务调度方式。在本章中，我们将对该数据调度算法和任务调度方式进行详细全面的介绍和描述。
4.1  标签化数据调度算法的描述
4.1.1算法的基本思想
本算法设定所有的数据原本均存储在磁盘中，设定初始数据块的标签表示Label=N， 以4M数据块为基本迁移单位，并且选取读写、冷热和生存周期标签为迁移标准。 判断标签的数据参数和每个标签所对应的字母表示如表4.1和4.2所示。
表4.1 数据参数及其符号表示
数据参数
符号表示
读操作次数
XR
写操作次数
XW
生存期
T
表4.2 标签的字母表示
标签种类
对应的字母表示
标签种类
对应的字母表示
热
H
冷
I
读倾向
R
写倾向
W
无明显倾向
Z
永久生存
P
用完即删
S
周期性读写
C


对于一个数据块：首先根据生存期标签即T值判断是否为永久生存数据块，若为永久生存数据块则Label=P并将其迁入NVM，否则判断是否为周期性读写数据块，若是周期性读写的数据块则Label=C并在下一周期到来时提前将该数据块迁入到NVM中，其余情况将数据块保留在磁盘中。然后根据冷热数据标签判断该数据块是否为“热”，如果是热数据块，则Label=H,接着判断是否为读倾向的数据块，若为读倾向的数据块，则Label=R并将其迁入NVM。其余情况均根据该数据块参数满足的判断条件将Label修改为对应的字母表示，并把数据块保留在磁盘中。
4.1.2算法的流程图
根据算法的基本思想画出该算法的流程图，如图4.1所示。其中XR表示该数据块的读操作次数，XW表示该数据块的写操作次数，T表示该数据块在系统中的生产期，X0表示冷热标签区分的阈值，Y0表示读倾向和无明显倾向标签区分的阈值，T0表示周期性读写数据的访问周期。

图4.1 标签化数据调度算法流程图
4.1.3算法的伪代码描述
在算法流程图的基础上，本文采用for语句和if语句对该算法进行伪代码描述。伪代码如下：
Migrating_data(block b)
For(each block b in disk)
{
   if T=0
{
Label=P;
   migrate b to NVM;
}
   else if T=T0
      { 
Label=C;
migrate b from disk to NVM before the next cycle comes; 
}
   else if XR+XW>X0
      {
        Label=H;
        if XR-XW>Y0 
          {
Label=R;
migrate b to NVM;
}
        else 
does not migrate b;
}
else 
{
Label=I;
does not migrate b;
}
}
4.1.4算法的举例
我们举一个简单的例子来说明该算法的整个过程，便于理解。
在本例中，我们设定数据块b的读操作次数，写操作次数，生存周期，初始标签值Label=N，冷热标签区分阈值，读倾向和无明显倾向间的区分阈值，我们根据数据的特性和算法的过程来评判最终数据块b部署在磁盘还是NVM上。
第一步：判断数据块的生存周期标签。因为，则数据仍保留在磁盘中，并进行下一步判断；
第二步：判断数据块的冷热标签。因为，所以该数据块的标签值Label=H，并进行下一步判断；
第三步：判断数据块的读写倾向标签。因为，所以该数据块的标签值再次变化为Label=R，并将该数据块从磁盘迁移到NVM中。
最终该数据的标签为读倾向，并且部署在NVM中。
4.2  操作系统常用调度算法
当数据已经合理的部署在存储系统中后，我们便需要考虑数据需求的主体对象——任务的调度。当有若干个任务已经到达服务器排队等待处理时，由于任务的执行时间有长有短，任务本身也有紧急度之分，所以采用什么样的标准合理地进行任务处理先后的排序也是十分重要的，这与服务上层应用的质量密切相关。首先，我们先介绍调度中几个相关时间的概念。
到达时间：任务到达服务器的时间； 开始时间：任务开始运行的时间；
等待时间：开始时间-到达时间；    完成时间：任务处理结束的时间；
服务时间：完成时间-开始时间，即任务需要运行的时间；
周转时间：完成时间-到达时间。
在本小节中，我们将介绍操作系统中常用的调度算法，详细描述这些算法的执行过程并简要分析了算法的适用场合和优缺点。
4.2.1先来先服务调度算法
先来先服务调度算法（First Come First Served, FCFS）[26]是最简单最基础的调度算法，也是一种非抢占式的算法。当任务调度中采用该算法时，系统根据任务到达的先后顺序进行排序，在后备等待队列中，在队列中位置排列靠前的任务优先被选中，将他们调入内存中，分配任务所需要的资源和数据，直到该任务运行结束或者发生某事件后不能继续运行下去。
该算法比较简单且容易实现，但是算法的效率不高，性能不好。有利于长作业和CPU繁忙型作业（进程）而不利于短作业和I/O繁忙型作业。
4.2.2短作业优先调度算法
短作业优先调度算法（Short Job First，SJF）[26]是以任务的服务时间为衡量标准的，也是一种非抢占式的算法。在任务调度中，该算法首先对每个任务的服务时间进行估计，然后从后备等待队列中挑选服务时间最短的一个或几个任务，将他们调入内存，分配相关的资源和数据开始处理。 
SJF算法简单且易于实现，优先照顾短任务，具有很好的性能，降低了平均等待时间，提高了吞吐量。但是该算法的效率不高，需要提前知道任务所需要运行的时间，而这个时间只能靠估计，精确度不高，如果服务时间的估计值过低则系统可能提前终止该任务。该算法没有考虑任务的等待时间，长任务在排队过程中被忽略，可能一直处于等待状态，容易出现饥饿现象，同时该算法完全未考虑任务的紧急程度，对较紧迫的任务不利，缺少剥夺机制，不能应用于实时系统。
4.2.3最短剩余时间优先调度算法
由于SJF算法本身是非抢占式的算法，当用于抢占式调度系统时，对应的算法即为最短剩余时间优先调度算法（Shortest Remaining Time，SRT）[26]，该算法是抢占式的算法。该算法首先挑选服务时间最短的任务处理，在该任务运行期间，一旦有新任务到达服务器，并且该新任务的服务时间比当前正在运行的任务的剩余服务时间短，则转而开始处理新任务；否则，当前任务继续运行。
该算法确保了一旦新的短任务进入系统，能够很快的得到处理。但是由于频繁的抢占和任务切换，会导致系统的开销大，该算法的实现代价较高，一般应用于实时系统。
4.2.4高响应比优先调度算法
高响应比优先调度算法（Highest Response Ratio Next，HRRN）[26]首先根据公式计算每个任务的响应比，公式如下：响应比=（等待时间+服务时间）/服务时间，然后挑选响应比最高的任务投入系统运行。
该算法既考虑了任务的等待时间，也考虑了任务的服务时间，综合了FCFS算法和SJF算法的特点。既照顾了短任务也考虑了使长任务不需要等待很长时间，提高了调度的性能。
4.3  任务调度方式的描述
基于操作系统调度算法的学习，从高响应比优先调度算法中得到启发，本文提出了基于最高紧迫服务比优先的任务调度方式。在本节中，我们将对该方式进行详细的描述。
4.3.1任务调度方式的基本思想
最高紧迫服务比优先的任务调度方式（Highest Emergency and Service Ratio First, HESRF）是一种非抢占式的方式，在每次进行任务调度时，首先根据用户的需要赋予任务一个衡量其紧迫度的值，再根据下列公式计算任务等待队列中每个任务的紧迫服务比，采用合理的排序法进行排序，根据紧迫服务比从高到低依次投入系统运行。
紧迫服务比=（紧迫度*70%+服务时间*30%）/服务时间
从我们定义的公式中可以分析出，影响任务调度的因素有两个：任务的紧迫度和服务时间，且任务的紧迫程度占较大比例，对任务执行的顺序有较大影响。当服务时间相差不大时，比较紧急的任务先执行；当紧急程度相差不大时，短任务先执行。该方式可以较好的满足用户对紧急任务处理的需求。
4.3.2任务调度方式的流程图
根据基本思想画出该方式的流程图，如图4.2所示。其中E为任务的紧迫度,TS为任务的服务时间，R为任务的紧迫服务比。

图4.2 基于最高紧迫服务比优先的任务调度方式流程图
4.3.3任务调度方式的伪代码描述
在上述流程图的基础上，本文采用for 语句和if语句对该方式进行伪代码描述。伪代码如下：
for(i=0;i<the number of tasks;i++)
  { 
input E,TS;
R=(E*0.7+TS*0.3)/TS;
}
sort tasks in descending order according to R
4.3.4任务调度方式的举例
同样的我们还是通过举一个简单的例子来说明该方式的过程。
在本例中，我们设置了五个任务，并合理设置任务的相关特性参数，如紧迫度、服务时间。其特性如下表4.3所示。
表4.3 任务特性参数
任务名
紧迫度
服务时间
A
1
5
B
10
100
C
70
1
D
90
80
E
50
20

第一步：根据上述公式计算每个任务的紧迫服务比R。
         
         

第二步：根据计算出的紧迫服务比R递减排序，则任务执行的顺序为C、E、D、A、B。
由结果可以看出，紧急程度较高的任务（紧迫度>50）均先执行，说明较好的满足了用户对紧急任务处理迫切的需求。
4.4  数据调度算法和任务调度方式的代码实现
在本小节中，我们进行上述数据调度算法和任务调度方式的代码实现。
4.4.1编程语言及运行环境介绍 
本实验采用Python编程语言以及Jupyter Notebook运行环境。本小节将对该编程语言和运行环境进行简单的介绍。
Python编程语言：Python最初由Guido van Rossum于1991年设计，由Python Software Foundation开发，这是一种动态的字节码编译语言，源代码中没有变量、参数、函数或者方法的类型说明。Python在运行时跟踪所有值的类型，并且标记在运行时没有意义的代码。 Python的语法简洁清晰，其特点是使用空白符作为语句缩进。该编程语言常应用于web编程、图形处理、文本处理、数据库编程等。
Jupyter Notebook运行环境：这是一款开源的网页应用程序，允许用户创建和共享包含实时代码、方程式、可视化和叙述文本的文档。Jupyter Notebook应用程序可以在本地桌面上执行，无需互联网访问，也可以安装在远程服务器上并通过互联网访问。Jupyter Notebook包含Jupyter Qt控制台、Jupyter Notebook和Notebook文件格式、内核消息协议（kernel messaging protocol）和其他组件，大多应用于数据的清理和转换、数值模拟、统计建模、数据可视化和机器学习等。
在对本实验所运用的编程语言和运行环境进行简单介绍后，接下来本文将对实验所设置的数据集和算法的代码实现做出陈述。
4.4.2标签化数据调度算法数据集设置及代码实现
本实验所用到的数据集采用随机生成的方式产生，在Python中设置每个数据的读操作次数范围、写操作次数范围和生存周期范围，然后通过random函数随机产生30个不同特性的数据。根据4.1节中陈述的算法基本思想，将这30个数据最终合理部署在磁盘和NVM上。在实验中，我们利用两个列表list2和list3分别代表NVM和磁盘。
标签化数据部署算法实现如下图4.3所示。

图4.3 标签化数据部署算法的代码实现
程序中，list2表示NVM,list3表示磁盘。第一个列表的输出即为list2，表明数据经过一系列的特征判断最终被迁移到NVM中。第二个列表的输出即为list3，表示数据经分析后存储在磁盘中为妥。
4.4.3任务调度方式数据集设置及代码实现
本实验所用到的任务及其特性也采用随机生成的方式，在Python中设置每个任务的紧迫值范围和服务时间范围，然后通过random函数随机产生10个不同特性的任务，根据4.3节中陈述的基本思想，得出任务处理的先后顺序。
最高紧迫服务比优先的任务调度方式代码实现如下图4.4所示。

图4.4 最高紧迫服务比优先的任务调度方式代码实现
输出的第一个列表为list15，它表示实验中10个任务对应的紧迫度的值，值越大表明任务越紧急。输出的第二个列表为li，它表示每个任务在输入相关特性参数之后，计算出的紧迫服务比按从高到低排序后的结果，在这个列表中，有10个组，代表10个任务，每个组里的第一个元素表明该任务的紧迫服务比，第二个元素表明该任务的编号。
由上图运行结果可以看出，根据最高紧迫服务比的排序，其任务的运行处理顺序为任务4、0、7、8、3、1、6、2、5、9。由结果可以看出，紧迫度较高的任务3、7、8均靠前执行，说明该方式有利于紧急度较高的任务，能较好的满足用户对紧急任务处理的需求。

4.5  本章小结
本章主要介绍了本文提出的标签化数据调度算法和基于最高紧迫服务比优先的任务调度方式。首先基于上一章标签化模型的建立详细描述了标签化数据调度算法的基本思想，通过流程图和伪代码清晰地呈现了算法的过程，并进行简单的举例具体说明算法的运行细节。接下来本章对操作系统常见的调度算法作了简单的陈述，包括先来先服务调度算法、短作业优先调度算法、最短剩余时间优先调度算法、高响应比优先调度算法，并分析了各算法的优缺点及适用场合。基于这些经典算法提出了最高紧迫服务比优先的任务调度方式，进行合理的任务调度，同时根据陈述的基本思想、流程图和伪代码详细地描述了该调度方式，然后通过简单的例子展现了该方式的运行细节，粗略的说明了该方式有利于紧急任务的处理。最后运用Python编程语言在Jupyter Notebook环境中进行数据调度算法和任务调度方式的代码实现，并简单分析了实验结果。

























第六章  总结与展望
6.1  本文总结
本文首先介绍基于数据标签化的混合存储架构下数据调度机制课题的研究背景，包括大数据、新型非易失性存储器、混合存储系统的相关内容，详细描述了大数据的特点及在传统存储架构下存在的瓶颈，新型非易失性存储器的优缺点以及混合存储架构的产生背景及优势，并且根据大数据分析任务的特点提出了标签化的概念。然后详细介绍了当前NVM/DRAM混合存储系统和HDD/SSD混合磁盘的发展进程与研究现状，主要是不同存储介质之间的数据交换算法的介绍，并根据当前的研究热点提出关注磁盘与NVM之间数据交换的观点。
通过仔细研究已有的数据调度算法和任务调度算法，并分析数据部署与任务执行的关系，分别提出了基于标签化的数据调度算法和基于最高紧迫服务比优先的任务调度方式。
（1）基于标签化的数据调度算法。设定所有的数据原本均存储在磁盘中，在CPU处理任务之前，根据标签化的定义给数据加上标签，然后将具有标签的数据依情况迁移到NVM中。
（2）基于最高紧迫服务比优先的任务调度方式。当待处理的任务达到服务器在排队等待处理时，根据任务的紧迫度和服务时间计算该任务的紧迫服务比，挑选紧迫服务比最高的任务投入系统进行处理。
最后通过Python编程语言进行数据调度算法和任务调度方式的实现，在任务调度方式的基础上通过是否加入标签化数据部署算法的结果对比，通过任务调用数据的总时间来评估标签化的性能。实验结果发现，标签化数据部署有利于减少任务访问数据的时间，对大数据操作延时的问题解决有一定的帮助。
本文提出的算法虽然在实验中通过对比可以得出其有效性，但是缺少理论上的证明，因为理论证明存在一定的难度，所以本文没有提及。同时本文进行的实验所用到的数据集和任务设置是随机的，不能很好地体现大数据的某些特征。
6.2  未来研究展望
针对本文存在的不足之处，提出下列未来研究展望。
（1） 论文中提出的算法缺少理论上的优化性验证，接下来需要对算法进行严谨详细的推理，从理论上证明标签化的有效性；
（2） 随着内存中存储的数据量和内存容量大小的变化，冷热标签和读写倾向标签中划分所设置的阈值也需要视情况变化。接下来需要深入的研究内存剩余容量和阈值设置的关系，使得该划分阈值合理且尽可能最优。
（3）本文主要是进行标签化的数据部署研究，所以文章中提出的任务调度方式只是为标签化验证实验提供一种任务处理排序的方法，并且只是通过代码实现粗略的说明了该方式具有一定的优越性。该任务调度方式需要进一步的研究，包括公式中参数的设置条件和约束、和其他任务调度方式相比是否存在优化性并进行严格的理论证明和实验验证。
（4）本实验的数据集和任务设置均为随机或者人为设置的，不具有代表性，可能不能体现大数据的特点，接下来需要寻找一些具体应用场景的数据集和任务，进行模拟实验的验证，才更能说明标签化的优化性。
（5）本实验的标签化有效性验证只是选取了两种数据部署方式——数据均存储在磁盘和最近不常使用算法部署与标签化数据部署进行对比，只能证明标签化数据部署方式优于这两种方式。接下来还需要将标签化数据部署方式和其他优化的数据部署方式进行对比，进一步证明标签化的有效性。













ii
    
